---
title: "Home_work_5"
author: "Тимофеев Игорь, 391 гр."
date: '7 декабря 2016 г '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

#Линейная регрессия, экспоненциальное сглаживание. Анализ.

#Первая линейная модель

Первой моделью будет линейная модель в зависимости от 13 переменных, 12 месяцев и времени. 

```{r}
df=read.csv("~/Загрузки/Книги/Программирование/Теорвер/Задачи/fancy.csv",header = TRUE)
fun=function(n,j){
  p=c(1:n)
  for(i in 0:(n-1)) { p[i+1]=ifelse(i%%12==j-1,1,0) }
  return(p)
}
sales=c()
sales=as.numeric(labels(df)[[1]][1:dim(df)[1]-1])
time=c()
time=as.numeric(labels(sales))
time[85:92]=85:92
sales[85:92]=NA
```

Вот исходный график:

```{r}
plot(time, sales, type = "l")
```

Видно, что сезонность мультипликативная, чтобы сделать ее аддитивной, нужно применить логарифм.

Построим график логарифма.

```{r}
month.01 <- fun(length(time),1)
month.02 <- fun(length(time),2)
month.03 <- fun(length(time),3)
month.04 <- fun(length(time),4)
month.05 <- fun(length(time),5)
month.06 <- fun(length(time),6)
month.07 <- fun(length(time),7)
month.08 <- fun(length(time),8)
month.09 <- fun(length(time),9)
month.10 <- fun(length(time),10)
month.11 <- fun(length(time),11)
month.12 <- fun(length(time),12)

####Находим модель для логарифма
log.sales=c()
log.sales=log(sales)
plot(time,log.sales, type = "l")
log.sales[85:92]=NA

```

Видно, что сезонность стала аддитивной, что подтверждает, что у изначального ряда была мультипликативная.

Нам нужна модель вида:

$y=a + b*t + \sum_{i=1}^{12}{month.i}$

Но при этом возникнут проблемы с линейной зависиомстью между переменными, так как month.i это вектора из 12 элементов, 11 из которых 0, а i равен 1, т.е. в сумме они дают вектор из единиц. Чтобы это исправить положение можно запихнуть поправку одного из месяцев в свободный член, тогда при интерпретации результатов a это будет значение в выбранном нами месяце, а в остальных переменных месяцов значение разницы между значением этого месяца и выбранного.


```{r}
df=data.frame(log.sales, time, month.01, month.02, month.03, 
              month.04, month.05, month.06, month.07, month.08, month.09, month.10, 
              month.11, month.12)

lin=lm(log.sales~time+month.02+month.03+month.04+month.05+month.06+month.07+
         month.08+month.09+month.10+month.11+month.12, df)
sum_lin=summary(lin)
log.sales2=c()
###Для красоты:
#log.sales2[1:84]=lin$fitted.values
#log.sales2[85]=7.60566+85*0.02239
#log.sales2[86]=7.60566+86*0.02239+0.25109
#log.sales2[87]=7.60566+87*0.02239+0.69527
#log.sales2[88]=7.60566+88*0.02239+0.38301
#log.sales2[89]=7.60566+89*0.02239+0.40804
#log.sales2[90]=7.60566+90*0.02239+0.44701
#log.sales2[91]=7.60566+91*0.02239+0.60829
#log.sales2[92]=7.60566+92*0.02239+0.58544
```

Получается такая модель:

```{r}
sum_lin
```

#Улучшение первой линейной модели.

Линейная модель должна удовлетворять нескольким условиям:

1)Выбрана правильная спецификация, в нашем случае нужно проверить дает ли сильное улучшение, если кроме переменной time в модели, мы добавим переменную time**2, а также насколько сильно влияют на модель различные месяцы.

В нашем случае и так видно, что тренд линейный.

2)Переменные модели не должны коррелировать между собой.

3)Гомоскедастичность.

4)Отствие автокорреляции случайных ошибок.

5)Нормальность распределения ошибок.

В нашей модели всего 84 наблюдения, а переменных 12. Это слишком много, есть правило, что на каждую переменную должно приходится по 30 наблюдений, в нашем случае на каждую переменную приходится 7 наблюдений. А слишком "хорошая" модель может привести к переобучению. Поэтому нужно как-то поудалять переменные.

Вспомним, что получилось в первой модели.

```{r}
lin=lm(log.sales~time+month.02+month.03+month.04+month.05+month.06+
         month.07+month.08+month.09+month.10+month.11+month.12)
summary(lin)
```


Можно предположить, что некоторые из месяцов не слишком сильно отличаются и их можно объединить в один, для это нужно взять за базовый месяц один из них и посмотреть на p-value. Подозрение падает на 7-8 месяцы, возьмем за базис 7.


```{r}
lin=lm(log.sales~time+month.01+month.02+month.03+month.04+month.05+month.06+
         month.08+month.09+month.10+month.11+month.12)
summary(lin)
```

Подозрение оправдалось, даже более того, за один месяц можно взять 6,7,8,9 и 10.

Вот получившаяся при этом модель:

```{r}
No_summer=month.06+month.07+month.08+month.09+month.10
lin=lm(log.sales~time+month.02+month.03+month.04+month.05+No_summer+month.11+month.12)
summary(lin)
```

Теперь првоерим 4 и 5. Возьмем за базис 4.

```{r}
lin=lm(log.sales~time+month.02+month.03+month.01+month.05+No_summer+month.11+month.12)
summary(lin)
```

Снова получилось, возьмем за одну переменную 4 и 5. Также можно объединить 1 и 2.

```{r}
May=month.05+month.04
Jan=month.01+month.02
lin=lm(log.sales~time+Jan+month.03+May+No_summer+month.11)
summary(lin)
```

Получилась такая модель. При этом R квадрат изменился не слишком сильно, в первой модели он был 0.9447, в новой 0.9373. Нарисуем то, что она предсказывает(желтым цветом - данные, черным - предсказания модели на 92 месяца, т.е. и на стырые месяцы и на новые 8).

```{r}
log.sales2=predict.lm(lin,df)
plot(time,log.sales2,type = "l")
lines(log.sales, col="yellow")
```

Теперь проверим другие пункты плана.

```{r}
plot(lin)
```

На последнем графике видно, что сильных выбросов нет.

```{r}
hist(lin$residuals)
shapiro.test(lin$residuals)
```

Шапиро тест показал, что распределение ошибок - нормальное.

```{r}
hist(rstudent(lin))
shapiro.test(rstudent(lin))
```

Немного улучшили показания Шапиро теста, убрав зависимость ошибок от иксов.

```{r}
cook.d=cooks.distance(lin)
plot(cook.d,ylab="cook.d")
abline(h=1/84, col="yellow")
abline(h=1, col="red")
```

Опять же смотрим на наличие точек, являющихся выбросами. Красной линии вообще нет на графике, за желтую выходит слишком много, так что убирать их все смысла не имеет. Хотя можно было бы убрать одно наблюдение наиболее сильно отклоняющееся от модели, т.к. оно также по крайней мере визуально сильно отклоняется от остальных, но в нашем случае погоды это не изменит.


```{r}
seas.2 <- rep(1:12, 16)[1:84]
boxplot(rstudent(lin)~seas.2)
```

Еще один график, рисующий boxplot для различных месяцев.

Теперь проверим на автокорреляцию случайных ошибок.

```{r}
library(car)
durbinWatsonTest(lin, method="normal")
```

По результатам теста видно, что автокорреляция есть и очень сильная.

Что с этим делать непонятно. В рамках метода линейной регрессии это, по видимому, никак не исправить.

Теперь, наконец, вернемся к изначальному ряду и посмотрим, что предсказал метод.

```{r}
####Конец.
sales2=exp(log.sales2)
plot(time,sales2,type = "l")
lines(sales, col="yellow")
```

Вроде даже неплохо предсказывает данные, по крайней мере основные изменения.

```{r}
df=data.frame(sales, sales2, time, month.01, month.02, month.03, 
              month.04, month.05, month.06, month.07, month.08, month.09, month.10, 
              month.11, month.12)
df[,1:2]
f=function(x){return(abs(x[1]-x[2]))}
r=apply(df[,1:2],1,f)
r=mean(r[!is.na(r)])
r0=mean(sales[!is.na(sales)])
error=r/r0*100
```

Средняя ошибка составила: `r error  ` процентов.


#Экспоненциальное сглаживание.

```{r}
######
##7
######
df=read.csv("~/Загрузки/Книги/Программирование/Теорвер/Задачи/fancy.csv",header = TRUE)
sales1=c()
sales1=as.numeric(labels(df)[[1]][1:dim(df)[1]-1])
time=c()
time=as.numeric(labels(sales1))
df=data.frame(time,sales1)

sales1=ts(df[,2], frequency = 12)
ser.g.HW <- HoltWinters(sales1, seasonal = "mult")
```

Предсказания модели:

```{r}
ser.g.HW$fitted
plot(ser.g.HW)
plot(fitted(ser.g.HW))
ser.g.predict <- predict(ser.g.HW, n.ahead=8)
ser.g.predict
df=data.frame(sales[13:92],c(as.vector(ser.g.HW$fitted[,1]),as.vector(predict(ser.g.HW, n.ahead=8))))
f=function(x){return(abs(x[1]-x[2]))}
r=apply(df[,1:2],1,f)
r=mean(r[!is.na(r)])
r0=mean(sales[!is.na(sales)])
error=r/r0*100
```

Средняя ошибка составила: `r error  ` процентов.
Теперь можно сранить основные итоговые графики экспоненциальной и линейной модели:

```{r}
plot2=ts.plot(sales1, ser.g.predict, ser.g.HW$fitted[,1], col=c("blue", "red", "orange"))
time=1:92
plot(time,sales2,type = "l")
lines(sales, col="yellow")
```
